from flask import Flask, jsonify, render_template
import mysql.connector
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import matplotlib.pyplot as plt
import pickle
import json
import os

app = Flask(__name__)

# Fetch orders data from MySQL
def fetch_orders_data():
    conn = mysql.connector.connect(
        host="localhost",
        user="root",
        password="root",
        database="pos_7"
    )

    query = """
        SELECT ID, order_date, ship_date, customer_id, product_id, product_name FROM orders
    """

    cursor = conn.cursor()
    cursor.execute(query)
    data = cursor.fetchall()
    cursor.close()
    conn.close()

    columns = ['ID', 'order_date', 'ship_date', 'customer_id', 'product_id', 'product_name']
    orders_df = pd.DataFrame(data, columns=columns)
    
    return orders_df

def market_basket_analysis(orders_df):
    # Clone the DataFrame to avoid modifying the cached object
    orders_df = orders_df.copy()
    
    # Convert order_date to datetime
    orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])

    # Aggregate products by customer to form transactions
    transactions = orders_df.groupby(['customer_id'])['product_name'].apply(list).reset_index()

    # Prepare data for MBA
    transaction_list = transactions['product_name'].tolist()

    # Transform the transaction data
    transaction_encoder = TransactionEncoder()
    transaction_encoder_ary = transaction_encoder.fit(transaction_list).transform(transaction_list)
    transaction_df = pd.DataFrame(transaction_encoder_ary, columns=transaction_encoder.columns_)

    # Apply Apriori algorithm to find frequent itemsets
    frequent_itemsets = apriori(transaction_df, min_support=0.001, use_colnames=True)

    # Generate association rules
    if not frequent_itemsets.empty:
        rules = association_rules(frequent_itemsets, metric="lift", min_threshold=0.001)

        # Filter out rules with confidence of 1 to avoid infinite conviction
        rules = rules[rules['confidence'] < 1]

        # Sort rules by lift in descending order and drop duplicates based on lift
        rules = rules.sort_values(by='lift', ascending=False).drop_duplicates(subset=['lift'])

        # Add count of occurrences
        rules['count'] = rules.apply(lambda row: sum(transaction_df[list(row['antecedents'])].all(axis=1) & transaction_df[list(row['consequents'])].all(axis=1)), axis=1)

        # Convert frozenset to list for JSON serialization
        rules['antecedents'] = rules['antecedents'].apply(lambda x: list(x))
        rules['consequents'] = rules['consequents'].apply(lambda x: list(x))

        return rules
    else:
        return pd.DataFrame()

def generate_insights(rules):
    insights = []
    for idx, rule in enumerate(rules.head(5).itertuples(), start=1):
        antecedents = ', '.join(rule.antecedents)
        consequents = ', '.join(rule.consequents)
        insight = f"{idx}. {antecedents} -> {consequents}"
        insights.append(insight)
    return insights

def plot_top_rules(rules):
    if not rules.empty:
        # Select relevant columns for display
        rules_display = rules[['antecedents', 'consequents', 'support', 'confidence', 'lift', 'count']]
        
        # Extract unique pairs for top 10 rules by lift
        seen_pairs = set()
        unique_top_rules = []
        for _, rule in rules.nlargest(10, 'lift').iterrows():
            pair = rule['antecedents'], rule['consequents']
            if pair not in seen_pairs:
                unique_top_rules.append(rule)
                seen_pairs.add(pair)
            if len(unique_top_rules) == 5:  # Adjusted to fetch top 5 unique rules
                break

        unique_top_rules_df = pd.DataFrame(unique_top_rules)
        
        # Save the unique top rules DataFrame to a pickle file
        with open('top_rules.pkl', 'wb') as f:
            pickle.dump(unique_top_rules_df, f)
        
        # Save the unique top rules DataFrame to a JSON file
        unique_top_rules_df.to_json('top_rules.json', orient='records')

        # Create a larger plot for the horizontal bar chart
        fig, ax = plt.subplots(figsize=(10, 6))

        colors = plt.cm.tab20.colors
        unique_top_rules_df.plot(kind='barh', x='antecedents', y='lift', ax=ax, color=colors, legend=False)
        ax.set_title('Top 5 Unique Association Rules by Lift')
        ax.set_xlabel('Lift')
        ax.set_ylabel('Antecedents -> Consequents')

        # Dynamically set x-axis limit based on maximum lift value
        max_lift = unique_top_rules_df['lift'].max()
        ax.set_xlim(0, max_lift * 1.1)

        # Adjust layout to ensure labels are fully visible
        plt.tight_layout()

        # Save the plot to the static directory
        os.makedirs('static', exist_ok=True)
        plot_filename = f'static/top_rules.png'
        plt.savefig(plot_filename, bbox_inches='tight')

        return plot_filename
    else:
        print("No association rules found. Try lowering the min_threshold value.")
        return None

@app.route('/api/mba-insights', methods=['GET'])
def get_mba_insights():
    orders_df = fetch_orders_data()
    rules = market_basket_analysis(orders_df)

    if not rules.empty:
        insights = generate_insights(rules)
        return jsonify({'insights': insights})
    else:
        return jsonify({'error': 'No association rules found. Try lowering the min_threshold value.'})

@app.route('/api/basic-barplot', methods=['GET'])
def get_basic_barplot():
    with open('top_rules.pkl', 'rb') as f:
        unique_top_rules_df = pickle.load(f)

    if not unique_top_rules_df.empty:
        plot_filename = plot_top_rules(unique_top_rules_df)
        return jsonify({'plot_filename': plot_filename})
    else:
        return jsonify({'error': 'No association rules found. Try running market basket analysis first.'})

@app.route('/api/mba-dataframe', methods=['GET'])
def get_mba_dataframe():
    orders_df = fetch_orders_data()
    rules = market_basket_analysis(orders_df)

    if not rules.empty:
        # Limiting to top 10 rows as requested
        top_10_rules = rules.head(10)
        top_10_rules_dict = top_10_rules.to_dict(orient='records')
        return jsonify(top_10_rules_dict)
    else:
        return jsonify({'error': 'No association rules found. Try lowering the min_threshold value.'})

if __name__ == '__main__':
    app.run(debug=True)
