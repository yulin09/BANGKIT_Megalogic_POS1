from flask import Flask, jsonify
import mysql.connector
import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
import matplotlib.pyplot as plt
import pickle
import os

app = Flask(__name__)

# Fetch orders data from MySQL
def fetch_orders_data():
    conn = mysql.connector.connect(
        host="localhost",
        user="root",
        password="root",
        database="pos_7"
    )

    query = """
        SELECT ID, order_date, ship_date, customer_id, product_id, product_name FROM orders
    """

    cursor = conn.cursor()
    cursor.execute(query)
    data = cursor.fetchall()
    cursor.close()
    conn.close()

    columns = ['ID', 'order_date', 'ship_date', 'customer_id', 'product_id', 'product_name']
    orders_df = pd.DataFrame(data, columns=columns)
    
    return orders_df

def market_basket_analysis(orders_df):
    # Clone the DataFrame to avoid modifying the cached object
    orders_df = orders_df.copy()
    
    # Convert order_date to datetime
    orders_df['order_date'] = pd.to_datetime(orders_df['order_date'])

    # Aggregate products by customer to form transactions
    transactions = orders_df.groupby(['customer_id'])['product_name'].apply(list).reset_index()

    # Prepare data for MBA
    transaction_list = transactions['product_name'].tolist()

    # Transform the transaction data
    transaction_encoder = TransactionEncoder()
    transaction_encoder_ary = transaction_encoder.fit(transaction_list).transform(transaction_list)
    transaction_df = pd.DataFrame(transaction_encoder_ary, columns=transaction_encoder.columns_)

    # Apply Apriori algorithm to find frequent itemsets
    frequent_itemsets = apriori(transaction_df, min_support=0.001, use_colnames=True)

    # Generate association rules
    if not frequent_itemsets.empty:
        rules = association_rules(frequent_itemsets, metric="lift", min_threshold=0.001)

        # Filter out rules with confidence of 1 to avoid infinite conviction
        rules = rules[rules['confidence'] < 1]

        # Sort rules by lift in descending order and drop duplicates based on lift
        rules = rules.sort_values(by='lift', ascending=False).drop_duplicates(subset=['lift'])

        # Add count of occurrences
        rules['count'] = rules.apply(lambda row: sum(transaction_df[list(row['antecedents'])].all(axis=1) & transaction_df[list(row['consequents'])].all(axis=1)), axis=1)

        # Create a column for the basket pair
        rules['basket_pair'] = rules['antecedents'].apply(lambda x: ', '.join([f"{item}" for item in list(x)])) + " -> " + rules['consequents'].apply(lambda x: ', '.join(list(x)))

        return rules
    else:
        return pd.DataFrame()

def prepare_output_for_plot(rules):
    if not rules.empty:
        # Select top 5 rules by lift and their lift values
        top_rules = rules.nlargest(5, 'lift')[['basket_pair', 'lift']]

        # Prepare data for JSON response
        categories = top_rules['basket_pair'].tolist()
        values = top_rules['lift'].tolist()

        response = {
            "categories": categories,
            "values": values
        }

        return response
    else:
        return {'error': 'No association rules found. Try lowering the min_threshold value.'}

@app.route('/api/basic-barplot', methods=['GET'])
def get_top_rules():
    orders_df = fetch_orders_data()
    rules = market_basket_analysis(orders_df)
    response_data = prepare_output_for_plot(rules)

    return jsonify(response_data)


if __name__ == '__main__':
    app.run(debug=True)
